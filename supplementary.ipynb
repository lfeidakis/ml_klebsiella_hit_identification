{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "metrics_file_path = \"gv_experiments/finetune/ResMLP_MAE_fingerprint_molformer_github_pretrained_on:ABCD_finetuned_on:ABCD_for_11_epochs_weight_decay:0.01_lr:0.5/metrics_seed0.json\"\n",
    "\n",
    "with open(metrics_file_path, \"r\") as f:\n",
    "    metrics = json.load(f)\n",
    "\n",
    "train_loss = metrics.get(\"train_loss\", [])\n",
    "val_loss = metrics.get(\"val_loss\", [])\n",
    "mcc = metrics.get(\"mcc_val\", [])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_loss, label=\"Train Loss\", marker=\"o\")\n",
    "plt.plot(val_loss, label=\"Validation Loss\", marker=\"o\")\n",
    "plt.plot(mcc, label=\"MCC\", marker=\"o\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training - Validation Losses and MCC over Epochs\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "#plt.savefig(\"loss_plot.png\")  \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "\n",
    "# Define the root folder containing all finetune subdirectories\n",
    "finetune_root = \"gv_experiments/finetune\"\n",
    "\n",
    "# Recursively find all \"metrics_seed0.json\" files in subdirectories\n",
    "metrics_files = glob(os.path.join(finetune_root, \"*/metrics_seed0.json\"), recursive=True)\n",
    "print(f\"Found {len(metrics_files)} metric files.\")\n",
    "\n",
    "# Initialize lists to store metrics from all runs\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "mcc_values = []\n",
    "\n",
    "# Determine the maximum epoch length across all runs\n",
    "max_epochs = 0\n",
    "\n",
    "# Load metrics and determine the maximum epoch length\n",
    "for file in metrics_files:\n",
    "    # Extract the parent folder name as the label\n",
    "    folder_name = os.path.basename(os.path.dirname(file))\n",
    "    \n",
    "    print(f\"Loading file: {file} (Run: {folder_name})\")\n",
    "    with open(file, \"r\") as f:\n",
    "        metrics = json.load(f)\n",
    "        train_losses.append(metrics.get(\"train_loss\", []))\n",
    "        val_losses.append(metrics.get(\"val_loss\", []))\n",
    "        mcc_values.append(metrics.get(\"mcc_val\", []))\n",
    "        max_epochs = max(max_epochs, len(metrics.get(\"train_loss\", [])))\n",
    "\n",
    "# Check if any metrics are loaded\n",
    "if len(train_losses) == 0 or len(val_losses) == 0 or len(mcc_values) == 0:\n",
    "    print(\"Error: No valid metric data found. Please check the metrics files.\")\n",
    "    exit()\n",
    "\n",
    "# Pad all metrics to the maximum epoch length with NaNs\n",
    "def pad_to_max_length(data, max_length):\n",
    "    padded_data = []\n",
    "    for run in data:\n",
    "        if len(run) < max_length:\n",
    "            # Pad with NaNs to the maximum length\n",
    "            padded_data.append(run + [np.nan] * (max_length - len(run)))\n",
    "        else:\n",
    "            # Truncate if the run is longer than the maximum length\n",
    "            padded_data.append(run[:max_length])\n",
    "    return padded_data\n",
    "\n",
    "# Apply padding and convert to numpy arrays with dtype=float to handle NaNs\n",
    "train_losses = np.array(pad_to_max_length(train_losses, max_epochs), dtype=float)\n",
    "val_losses = np.array(pad_to_max_length(val_losses, max_epochs), dtype=float)\n",
    "mcc_values = np.array(pad_to_max_length(mcc_values, max_epochs), dtype=float)\n",
    "\n",
    "# Avoid plotting if metrics are empty\n",
    "if not train_losses.size or not val_losses.size or not mcc_values.size:\n",
    "    print(\"Error: One or more metric arrays are empty.\")\n",
    "    exit()\n",
    "\n",
    "# Calculate the mean and standard deviation while ignoring NaNs\n",
    "def calculate_mean_and_std(data):\n",
    "    mean = np.nanmean(data, axis=0)\n",
    "    std = np.nanstd(data, axis=0)\n",
    "    return mean, std\n",
    "\n",
    "epochs = np.arange(max_epochs)\n",
    "\n",
    "# Calculate mean and standard deviation for each metric\n",
    "train_mean, train_std = calculate_mean_and_std(train_losses)\n",
    "val_mean, val_std = calculate_mean_and_std(val_losses)\n",
    "mcc_mean, mcc_std = calculate_mean_and_std(mcc_values)\n",
    "\n",
    "# Plot smooth trend lines with shaded areas for standard deviation\n",
    "fig, axs = plt.subplots(1, 3, figsize=(20, 6))\n",
    "\n",
    "# Training Loss Trend\n",
    "axs[0].plot(epochs, train_mean, color='blue', label='Train Loss Mean')\n",
    "axs[0].fill_between(epochs, train_mean - train_std, train_mean + train_std, \n",
    "                    color='blue', alpha=0.2, label='±1 Std Dev')\n",
    "axs[0].set_title(\"Training Loss Trend\")\n",
    "axs[0].set_xlabel(\"Epoch\")\n",
    "axs[0].set_ylabel(\"Loss\")\n",
    "axs[0].legend()\n",
    "\n",
    "# Validation Loss Trend\n",
    "axs[1].plot(epochs, val_mean, color='green', label='Validation Loss Mean')\n",
    "axs[1].fill_between(epochs, val_mean - val_std, val_mean + val_std, \n",
    "                    color='green', alpha=0.2, label='±1 Std Dev')\n",
    "axs[1].set_title(\"Validation Loss Trend\")\n",
    "axs[1].set_xlabel(\"Epoch\")\n",
    "axs[1].set_ylabel(\"Loss\")\n",
    "axs[1].legend()\n",
    "\n",
    "# MCC Trend\n",
    "axs[2].plot(epochs, mcc_mean, color='purple', label='MCC Mean')\n",
    "axs[2].fill_between(epochs, mcc_mean - mcc_std, mcc_mean + mcc_std, \n",
    "                    color='purple', alpha=0.2, label='±1 Std Dev')\n",
    "axs[2].set_title(\"MCC Trend\")\n",
    "axs[2].set_xlabel(\"Epoch\")\n",
    "axs[2].set_ylabel(\"MCC\")\n",
    "axs[2].legend()\n",
    "\n",
    "# Unified title and layout\n",
    "plt.suptitle(\"Metric Trends with Variance Across Fine-tuning Runs\", fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "\n",
    "# Save the plot to a file and show it\n",
    "output_path = os.path.join(finetune_root, \"metric_trend_waves.png\")\n",
    "plt.savefig(output_path)\n",
    "print(f\"Metric trend plot saved to {output_path}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "file_path = \"ABCD/ResultsAndCheckpoints/ABCD/MAE_Mol/new_loader_MAE_Mol_ABCD_DRIAMS-any_specific_results/test_set_seed0.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df = df[(df[\"species\"] == \"Klebsiella pneumoniae\")]\n",
    "\n",
    "df[\"Predicted_Binary\"] = (df[\"Predictions\"] >= 0.5).astype(int)\n",
    "\n",
    "df[\"response\"] = df[\"response\"].astype(int)\n",
    "\n",
    "mcc = matthews_corrcoef(df[\"response\"], df[\"Predicted_Binary\"])\n",
    "\n",
    "print(f\"Matthews Correlation Coefficient (MCC): {mcc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7x/p33f63cs72qbf0n4fz1qpztc0000gp/T/ipykernel_15909/1017262428.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  klebsiella_data.rename(columns={'drug': 'Name'}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_file = \"processed_data/DRIAMS_combined_long_table.csv\"\n",
    "data = pd.read_csv(csv_file)\n",
    "\n",
    "klebsiella_data = data[data['species'] == \"Klebsiella pneumoniae\"]\n",
    "\n",
    "klebsiella_data.rename(columns={'drug': 'Name'}, inplace=True)\n",
    "\n",
    "percentages = klebsiella_data.groupby('Name')['response'].mean() * 100\n",
    "\n",
    "sample_counts = klebsiella_data.groupby('Name')['sample_id'].nunique()\n",
    "\n",
    "result = pd.DataFrame({\n",
    "    'percentage_1_responses': percentages,\n",
    "    'distinct_sample_count': sample_counts\n",
    "}).reset_index()\n",
    "\n",
    "result.to_csv(\"klebsiella_data/1klebsiella_response_stats.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7x/p33f63cs72qbf0n4fz1qpztc0000gp/T/ipykernel_15909/4010176815.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  klebsiella_data.rename(columns={'drug': 'Name'}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_file = \"processed_data/DRIAMS_combined_long_table.csv\"\n",
    "data = pd.read_csv(csv_file)\n",
    "\n",
    "# Extract all drug names from the entire dataset\n",
    "all_drugs = data['drug'].unique()\n",
    "\n",
    "# Filter Klebsiella pneumoniae data\n",
    "klebsiella_data = data[data['species'] == \"Klebsiella pneumoniae\"]\n",
    "\n",
    "# Rename column for consistency\n",
    "klebsiella_data.rename(columns={'drug': 'Name'}, inplace=True)\n",
    "\n",
    "# Compute the percentage of response == 1\n",
    "percentages = klebsiella_data.groupby('Name')['response'].mean() * 100\n",
    "\n",
    "# Compute distinct sample counts\n",
    "sample_counts = klebsiella_data.groupby('Name')['sample_id'].nunique()\n",
    "\n",
    "# Create a result DataFrame with only the drugs present in Klebsiella data\n",
    "result = pd.DataFrame({\n",
    "    'percentage_1_responses': percentages,\n",
    "    'distinct_sample_count': sample_counts\n",
    "}).reset_index()\n",
    "\n",
    "# Ensure all drugs from the original dataset are included\n",
    "all_drugs_df = pd.DataFrame({'Name': all_drugs})\n",
    "\n",
    "# Merge with the result, filling missing values with NaN\n",
    "final_result = all_drugs_df.merge(result, on='Name', how='left')\n",
    "\n",
    "# Save to CSV\n",
    "final_result.to_csv(\"klebsiella_full_response_stats.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation between percentage_1_responses and Rank: 0.7447769621682666\n"
     ]
    }
   ],
   "source": [
    "## KNOWN DRUG SPEARSON CORRELATION COMPUTATION ## WINDSURFING\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "input_type = \"raw_morgan\"\n",
    "# Load the data\n",
    "percentage = pd.read_csv(\"klebsiella_data/klebsiella_response_stats.csv\")\n",
    "proba = pd.read_csv(f\"rankings/known_drug_ranks_{input_type}_windsurfing.csv\")\n",
    "\n",
    "# Rename columns\n",
    "proba.columns = [\"Name\", \"Placement_Score\", \"Rank\"]\n",
    "\n",
    "# Merge the data frames on the \"Name\" column\n",
    "data = pd.merge(percentage, proba, on=\"Name\")\n",
    "\n",
    "# Quality Control: Filter rows where distinct_sample_count > 100\n",
    "data = data[data[\"distinct_sample_count\"] > 100]\n",
    "\n",
    "# Compute Spearman rank correlations\n",
    "correlation_rank = data[\"percentage_1_responses\"].corr(data[\"Rank\"], method=\"spearman\")\n",
    "#correlation_probability = data[\"percentage_1_responses\"].corr(data[\"Average_Probability\"], method=\"spearman\")\n",
    "\n",
    "# Print the results\n",
    "print(f\"Spearman correlation between percentage_1_responses and Rank: {correlation_rank}\")\n",
    "#print(f\"Spearman correlation between percentage_1_responses and Average_Probability: {correlation_probability}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## AVERAGE PROBABILITY RANKING METHOD ##\n",
    "\n",
    "def calculate_probability_ranking(input_directory, exclusion_file, output_file):\n",
    "    \"\"\"\n",
    "    Processes prediction files and aggregates probability data for ranking.\n",
    "    Merges aggregated data with compound lists and saves ranked results.\n",
    "\n",
    "    Args:\n",
    "        input_directory (str): Directory containing prediction files.\n",
    "        excluded_samples (set): Set of sample IDs to be excluded.\n",
    "        output_file (str): Path to save the ranked results.\n",
    "\n",
    "    Returns:\n",
    "        .csv: Average probability - based ranking. \n",
    "    \"\"\"\n",
    "    excluded_samples = load_excluded_samples(exclusion_file)\n",
    "    aggregate_dict = {}\n",
    "\n",
    "    for file_name in os.listdir(input_directory):\n",
    "        # Skip files containing excluded sample IDs\n",
    "        if any(sample in file_name for sample in excluded_samples):\n",
    "            print(f\"Excluding file: {file_name}\")\n",
    "            continue\n",
    "\n",
    "        if file_name.endswith(\".csv\"):\n",
    "            file_path = os.path.join(input_directory, file_name)\n",
    "            print(f\"Processing file: {file_path}\")\n",
    "\n",
    "            try:\n",
    "                df = pd.read_csv(file_path, usecols=[\"SMILES\", \"Predictions\"])\n",
    "            except ValueError:\n",
    "                print(f\"Skipping file {file_path}: Missing required columns.\")\n",
    "                continue\n",
    "\n",
    "            df = df.drop_duplicates(subset=[\"SMILES\"])\n",
    "\n",
    "            for _, row in df.iterrows():\n",
    "                smiles = row[\"SMILES\"]\n",
    "                prediction = row[\"Predictions\"]\n",
    "\n",
    "                # Accumulate predictions for each SMILES\n",
    "                if smiles in aggregate_dict:\n",
    "                    aggregate_dict[smiles][\"total\"] += prediction\n",
    "                    aggregate_dict[smiles][\"count\"] += 1\n",
    "                else:\n",
    "                    aggregate_dict[smiles] = {\"total\": prediction, \"count\": 1}\n",
    "\n",
    "    if aggregate_dict:\n",
    "        # Compute the average probability for each compound\n",
    "        aggregate_df = pd.DataFrame([\n",
    "            {\"SMILES\": smiles, \"Average_Probability\": data[\"total\"] / data[\"count\"]}\n",
    "            for smiles, data in aggregate_dict.items()\n",
    "        ])\n",
    "\n",
    "        # Sort by increasing average resistance probability\n",
    "        aggregate_df = aggregate_df.sort_values(by=\"Average_Probability\", ascending=True)\n",
    "\n",
    "        # Merge aggregate_df with the original vendor compound list and rank \n",
    "        df1 = aggregate_df\n",
    "        df2 = pd.read_csv(\"compound_lists/Enamine_Hit_Locator_with_fingerprints.csv\")\n",
    "        lf = pd.merge(df1, df2, on=\"SMILES\")\n",
    "        lf = lf[[\"Name\", \"SMILES\", \"MW\",\"ClogP\",\"HBD\",\"TPSA\",\"RotBonds\",\"Morgan_Fingerprint\", \"Average_Probability\" ]]\n",
    "        lf = lf.sort_values(by=\"Average_Probability\", ascending=True)\n",
    "\n",
    "        # Save ranked results\n",
    "        lf.to_csv(output_file, index=False)\n",
    "        print(f\"Ranking complete. Results saved to {output_file}\")\n",
    "    else:\n",
    "        print(\"No valid data was processed.\")\n",
    "\n",
    "\n",
    "if method == \"probability\":\n",
    "    \"\"\"\n",
    "    - Aggregates resistance probability predictions across samples.\n",
    "    - Computes the average probability for each compound.\n",
    "    - Sorts compounds by increasing resistance probability.\n",
    "    \"\"\"\n",
    "    calculate_probability_ranking(input_directory, excluded_samples_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## KNOWN DRUG PROBABILITY AGGREGATION FUNCTION ##\n",
    "\n",
    "def calculate_known_drug_probabilities(input_directory, exclusion_file, output_file):\n",
    "    \"\"\"\n",
    "    Process prediction files and aggregate data for known drug probabilities.\n",
    "    Save the aggregated predictions to a CSV file.\n",
    "\n",
    "    Args:\n",
    "        input_directory (str): Directory containing prediction files.\n",
    "        excluded_samples (set): Set of sample IDs to be excluded.\n",
    "        output_file (str): Path to the output file where results will be saved.\n",
    "    \"\"\"\n",
    "    excluded_samples = load_excluded_samples(exclusion_file)\n",
    "    aggregate_dict = {}\n",
    "\n",
    "    for file_name in os.listdir(input_directory):\n",
    "        # Skip files containing excluded sample IDs\n",
    "        if any(sample in file_name for sample in excluded_samples):\n",
    "            print(f\"Excluding file: {file_name}\")\n",
    "            continue\n",
    "\n",
    "        # Process only CSV files\n",
    "        if file_name.endswith(\".csv\"):\n",
    "            file_path = os.path.join(input_directory, file_name)\n",
    "            print(f\"Processing file: {file_path}\")\n",
    "            \n",
    "            try:\n",
    "                # Load predictions from CSV file\n",
    "                df = pd.read_csv(file_path, usecols=[\"Drugs\", \"Predictions\"])\n",
    "            except ValueError:\n",
    "                print(f\"Skipping file {file_path}: Missing required columns.\")\n",
    "                continue\n",
    "            \n",
    "            # Remove duplicate drug entries within the file\n",
    "            df = df.drop_duplicates(subset=[\"Drugs\"])\n",
    "            \n",
    "            # Aggregate predictions for each drug\n",
    "            for _, row in df.iterrows():\n",
    "                name = row[\"Drugs\"]\n",
    "                prediction = row[\"Predictions\"]\n",
    "                \n",
    "                if name in aggregate_dict:\n",
    "                    aggregate_dict[name][\"total\"] += prediction\n",
    "                    aggregate_dict[name][\"count\"] += 1\n",
    "                else:\n",
    "                    aggregate_dict[name] = {\"total\": prediction, \"count\": 1}\n",
    "    \n",
    "    if aggregate_dict:\n",
    "        # Convert aggregated data into a DataFrame\n",
    "        aggregate_df = pd.DataFrame([\n",
    "            {\"Name\": names, \"Average_Probability\": data[\"total\"] / data[\"count\"]}\n",
    "            for names, data in aggregate_dict.items()\n",
    "        ])\n",
    "        \n",
    "        # Sort predictions in ascending order of probability\n",
    "        aggregate_df = aggregate_df.sort_values(by=\"Average_Probability\", ascending=True)\n",
    "\n",
    "        # Save to CSV file\n",
    "        aggregate_df.to_csv(output_file, index=False)\n",
    "        print(f\"Results saved to {output_file}\")\n",
    "    else:\n",
    "        print(\"No valid data was processed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
